{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Analysis on YouTube Comments"
   ]
  },
  {
   "attachments": {
    "youtube.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAkACQAAD/4REQRXhpZgAATU0AKgAAAAgABAE7AAIAAAAYAAAISodpAAQAAAABAAAIYpydAAEAAAAuAAAQ2uocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE11c3RhZmEgRnVya2FuIEtvbGFuY8SxAAAFkAMAAgAAABQAABCwkAQAAgAAABQAABDEkpEAAgAAAAMxNwAAkpIAAgAAAAMxNwAA6hwABwAACAwAAAikAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMToxMToyOCAyMzoyNDoyMAAyMDIxOjExOjI4IDIzOjI0OjIwAAAATQB1AHMAdABhAGYAYQAgAEYAdQByAGsAYQBuACAASwBvAGwAYQBuAGMAMQEAAP/hCypodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIxLTExLTI4VDIzOjI0OjIwLjE3MzwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5NdXN0YWZhIEZ1cmthbiBLb2xhbmPEsTwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAEdAeUDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6RooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooARuFri9d+J2jaLdvap5l3MhwwiA2qfQkmt7xVfNp3hXULmM4dIW2n0JGK+aixZizHJJyTXBjMTKlaMd2fSZJlVPHc1Sq9EesS/GiMH9zpTEf7Un/wBaoD8aZv4dJT8ZT/hXl1JXm/XK/c+qWQ5evsfiz08/Gm6zxpEOP+up/wAKcvxouP4tJj/CU/4V5dS0vrlf+Yr+wsv/AOff4v8AzPVE+NDZ+fSRj2l/+tV+1+MmmySKLuxuIQTyyENj+VeOUVSxtZdTOXD+AktItfNn0/peqWmr2SXdhMs0L9GH8qh1XxHo+htGusalb2ZlBKCZ9u7HXFebfBjUH+13+nsxKbBMoPY5wf5ij9ofRRe+CLfUkXMljOOR2V+D+oFe1Qqe1pqR8FmGE+p4mVG90j1Ow1C01SyS7064jubeTOyWNsq2Dg8/UVnXnjHw7p989ne6zZwXKHDRPKAwP0rzz9nzVxcfD+7tXbmxuGABPRSN38815RosDeOPjnvbMkU+otcOP+matux9MDFbHAfWasGUMpyCMg+tLSDCqB0AGKXNABRRRQBj6l4s0DR7s2uqava2s4AJjlkAODVT/hYPhL/oYbD/AL/CuP8AH/waHjXxK+r/ANr/AGXMSp5flbug9c18+W/hsz+PF8OfacZvPsvnbf8AaxnFAH2BpfinQ9bumttJ1W1vJlQuY4ZAxC5Az+orWrzP4c/CIeAvEU2p/wBq/bPNtmg8vy9uMspz1/2a9MoAR3CRs56KMmuH8P8Axd8M+JvEEGj6ZJcNdzlggeLA+VSx5z6A12lz/wAesv8AuH+VfJ/wY/5LLpX+9P8A+inoA+taKMj1ooAKKMj1ooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5T4lzeV4CvyOp2L+bivn2vfPilGX8B3hH8Lxn/wAfFeBivDzD+KvQ/QuGEvqkn/e/RC1e0NFk16xSRQytOgIIyCM1RrQ0D/kYrD/r4T+dcMPiR9FX/hS9Gep+JfhTZ3ytc6GwtZyMmI/cY/0ryrVdF1DRLowalbPC/bI4b3B719KXN9a6fZme8mSGJRks5wK8n8c/EWx1a3k07TbOO4jJwbiZenuo/rXq4uhRS5r2Z8ZkuYY+c1T5eePd9Pmea0UlLXkH3J3nwhk2+L5F/vW5H6ivVfGOjrr3g7U9NYZM9u6p7Nj5T+BxXk/wkXPjIn0gb+le5npXvYH+Cfm3EVvrz9EfKvwt8St4ZsfFsEjbD/Z7On/XRWCAf+PfpWt8BbKOym1zxVeg+TptqQCR1yCzfkF/WuN+JWky+GviHrNjESkM0m9cdGR8Pj8Dx+FeqaDo7aH+zLqExXZNfQPOx77WwB+n867j544a21zxr8VvGUtppurS2gIaRY0naKOKMHjO3r1A/GtHwD498R+EviGnh7xFfTXVu119knSeQyeW+7aGDHnGf0p/7OAB8e6ge/8AZzf+jErl/iM7Q/GTVpIztZb/AHAjscigDvvjz4o1rRfF1jDpOp3NpE9ruZYZCoJ3Hniui8Ra7qdv+zbY6rDfTpfvb2zNcK5Dklhk5964T9oU7vFmlE97AH/x411nif8A5NV07/r1tf8A0NaAHfAHxBq2uf2z/a+oXF55QTZ50hbbnPTNeZaf/wAl3T/sMf8AtSu7/Zs/5jv0j/rXCaf/AMl3T/sMf+1KAO8+PnibWtE8VadDpOp3NnG9qWZYZCoJ3deK3dW13VIv2ZoNWjvp11BoIGNyHO8kyqDz16Vxv7SP/I4aX/15n/0Kuj1r/k022/69rf8A9HLQBH8CfEOr64uuDV9QuLwRRrsE0hbbnPTNeR+BZ9Wt/H1o3h2JZdSZpY4A3QFkZdx+gJP4V6V+zn/zMH/XJP8A2auP+DH/ACWXSv8Aen/9FPQAzxHqfjrwJ402arrdzJeptmBW4d4pAefunAx2xivbfHHxJl0b4V2WuaeFW81SNBBnkIWGSfw5/GvNf2j1A8caew6myAP/AH0aqfEGV2+C/gVCeCjn8sigChZ6d4917wdfeMk1+7+zWrMWT7ZIrMF+8QBxgV6j8CfHuoeJ7K90rWpjcXNkoeOZj8zIeMH1we/vXC+FfiRoOkfBm98M3hn+3zxXCqFjyuXzjml/Z0YjxzfAHg2Zz/30KAPpeiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAOb8fwG48D6igGcRhvyIP9K+dq+pr61S+sJ7WXlJkKN9CMV8/694E1nRr6RFtJbmDJ2SxLuBHuB0NeTj6UpNSSPtOG8ZSpxnRnKzburnNVNZ3LWd7DcxgFoXDgHoSKc+n3sfElnOp94iP6VGbacdYJB/wA15VpJn2TlTmrXTRoa14j1PX5/M1K5ZwPuxjhV+grLp/ky/88n/75NKLeY9IZD/wE05OUndk040qUVGFkiOiphZ3Tfdtpj9IzVq28PaveSBLfTrlixwP3RFJRk9kOValFXlJL5nZ/BuAv4mu5ccJbdfcsK9pri/h14Sl8M6ZJJe4+13JBdQc7AOgrtK+hwsHCkk9z8wzjEwxOMlODutvuPl39oEf8XKX/r1T+Zr1zVbZ7r9nkxxLkjRkfA9FjBP8qwvif8I9Y8a+Lhqmn3drDEIVj2y7s5BPoK9N0bR/snhGz0e92S+VaLby4+62FwfwrqPJPnz9nOZI/H96rsAX09gue53oa5rx1H/afxq1GC2O8zamIlx3JYD+ddzqfwK8S6Pr8l94N1SNIyzGI+YY5Iwe2ehrZ+HvwRvtJ8Sxa74qvIp5oX8yOGMlsydmZj6dfrQByX7Q6FPFulg9rED/AMeNdT4nkQ/sracAwz9ntR177xXQ/F74X3PjpbS90meKK9tVMeyXIWRSc9exzXI6J8Ddfn0Wa18SatuhihcWVksrNHHKQcMewGfSgBP2bP8AmO/SP+tcJp//ACXdP+wx/wC1K9r+E3w41LwF/aP9p3ME/wBqC7PJzxjPXP1rm7X4La3B8SF8Qte2hthf/adg3btu7OOnWgDA/aR/5G/S/wDrzP8A6FXQa1In/DJ1sNwybeAAZ7+ctdL8XvhlceO4bS60ueKK+tAUCy5CyKecZHQ5FcfoPwN16bSpbbxNqubaKJ/slkkrNGspBwx7AAnPFAFb9nP/AJmD/rkn/s1cd8GWC/GTSixAG6cZP/XJ69k+FXwz1TwL/af9pXNvN9sRVTys8Yz1z9a47SP2e9Xh1CWe+1aGHCM0ElsW3JJ/CfpQBkftFXUc/j+0hjYM0FmocDsSxP8ALFO+I2nyw/BTwRIwOEUhvbcNwq3B8AvE2oeIxL4g1OGW3Lgy3HmM8ki/iOuPWvZvFngew8T+DToDgQRxoot3Uf6plHBH8vpQB5n8LtF8MN8Hpdb1rSbS8ltGneRpIwWIU5xk+1b3ws8VeFPEWuXcXhvw6ul3EMG6SVY1G5dwGMiuDHwR8eWdvPpVlq0P9mztmRVnZUf3K4r1X4X/AA1i8AabOZp1ur+6x50qjCgDoo9qAO8ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAjaJGPzKp+opptYT1iT/vmpqKVh3ZB9jg/wCeEf8A3yKX7JAP+WMf/fIqaiiyDmfciFvGOkaj8KkCgDpS0UxXYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUhYDrQAtIzqqksQAOpNcd4n+ImnaEzW1qPtt70EUZyFPua5ePSPGXjgiXU7ltNsW5EfTI/wB3r+dc8q6T5YK7PTo5dOUPa1pKEO76+i3Z22rePPD+kkrPfpJIP+WcPzn9K5mf4v2zvt0zS7i5PbLbf5ZrX0n4YaBp6q1xE17KP4pzxn6Cupt9Ms7RAltawxKOgRAKnlry3aX4mnPl1LSMJTfm7L8DzkfEfxLNzb+F5Svbhz/Sg/EXxPFzP4XmA/3XH9K9OCAdAB+FBjB6gflT9lU/nf4E/XML/wBA6+9/5nm0PxejiYLqmkXFse+1s/zAro9L+IXh7VWCRXywyH+Cf5D+tdBPYWtyhSe3ikU9QyA5rmNV+Gnh/UtzR232OQ/xwHH6dKXLXjs0yvaZdV0lCUPR3X3M61JEkQMjBlI4IPWnV5PL4a8XeDGM+hXrX9opyYTycf7p/pXQeGfiTY6rKtnqqfYL3ptfhWPse340411flmrMirl0lB1aElOPluvVbncUU0OGAI5Bp1dJ5YUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRSEigBssixRl3YKqjJJ7CvMfEXjLUPEupnQvB4Zg2VluV4474PYe9HjPxFeeItZXwv4cJOW23Eqnj3GfQd67Pwv4WtPDOmrBbKHmYZlmI5c/4VySlKtLkhst3+h7VKnTwNNVqyvN/DHt5v9EZfhT4fWGghbi7UXd+eWlcZCn2H9a7HAFLRXRCEYK0UeZXxFXET56ruw6UUUVZgFFFFABRRRQAm0Vy3irwHpviKJpVQW16B8s6Dqff1rqqKmUIzVpI2o1qlCanTdmeUaL4o1XwVqa6N4rDPaHiK45O0eue4/lXqUFxHcwpLA6yRuMqynIIrN8Q+HrPxHpr2l6g55SQD5kPqK8/8M61e+CfEB8Oa8xNo7f6PMegz0I9j+lcqcqMuWWsXs+x6s4U8wpurSVqi3XR+a8+6PV6KajBhkHIp1dh4gUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFcf8QvEx0DRDFat/pt1lIgOoHc11ztsUsTgAZNeUWCf8Jx8UZbqXL2GnHCg9Dg8fmQTXPXm0lGO7PTy6jCU3Wq/BBXfn2XzZ03w88KDQ9K+13iZv7sb5GPJUdlrswMUgAUYFLWsIKEVFHHiK88RVdWe7GTTxW0LS3EixRoMs7nAA9zXOv8R/BcblH8VaOrKcEG+j4/WvCf2ovF+oR6xYeGrWd4bPyPtE4Q48xiSAD7ADpXzuST1qzA+/P+Fk+Cf+hs0b/wOj/xo/4WT4J/6GzRv/A6P/GvgOigD78/4WT4J/6GzRv/AAOj/wAaP+Fk+Cf+hs0b/wADo/8AGvgOigD78/4WT4J/6GzRv/A6P/Gj/hZPgn/obNG/8Do/8a+A6KAP0CtviB4QvJ1htfE2kzSt0RL2Mk/hmugVldQyEEHkEd6/N5WZTlSQfUGvrL9mXxZqGueFL7StSma4/s118mRzlgjfw574IP50Ae4Vy3jnwrH4j0R/LGLyAF4HHXPp+NdTSHpUzipx5Wa0a06FRVIPVHDfDXxNJqWmPpmoEi+svkO48so4/TpXdDmvJ/FULeDviDZ67a5W1u2xMB0/2h+PWvVYZFlhSRCGVhkEd6xoSdnCW6O/MaUOaOIpfDNX9H1Q+iiiug8sKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiikd1jjZ3IVVGST2FAC0Vkf8JZoH/QXs/+/wAtH/CWaB/0F7P/AL/LUc8e5t7Cr/K/uNeisj/hLNA/6C9n/wB/lo/4SzQP+gvZ/wDf5aOePcPYVf5X9xr0Vkf8JZoH/QXs/wDv8tH/AAlmgf8AQXs/+/y0c8e4ewq/yv7jXorI/wCEs0D/AKC9n/3+Wj/hLNA/6C9n/wB/lo549w9hV/lf3GvRWR/wlmgf9Bez/wC/y0f8JZoH/QXs/wDv8tHPHuHsKv8AK/uNeisj/hLNA/6C9n/3+Wj/AISzQP8AoL2f/f5aOePcPYVf5X9xr0Vkf8JZoH/QXs/+/wAtH/CWaB/0F7P/AL/LRzx7h7Cr/K/uNeisj/hLNA/6C9n/AN/lo/4SzQP+gvZ/9/lo549w9hV/lf3GvRWR/wAJZoH/AEF7P/v8tH/CWaB/0F7P/v8ALRzx7h7Cr/K/uNeisj/hLNA/6C9n/wB/lo/4SzQP+gvZ/wDf5aOePcPYVf5X9xX8a6p/ZHhK+uQcP5exPq3H9axvhXpQsfCa3Lr+9vHMhPqOgrG+KWv2GpaRZ2Wm3sNyZbgbxE4bAx3x716Ho1oLHRbO2UYEUKLj6CudNTrtrovzPTqRdDLlFqznL8F/wS9RRRXWeMfIn7UH/JTrf/rxX/0Jq8Xr2j9qD/kp1v8A9eK/+hNXi9AHo2gfArxt4l0K11fSrS1e0ul3xM9yqkjOOn4Vo/8ADNvxD/58rP8A8C1ru/h9+0J4b8KeAtK0S+0zVZbiziKO8MSFCdxPBLg966T/AIal8I/9AjW/+/Mf/wAXQB5B/wAM2/EP/nys/wDwLWj/AIZt+If/AD5Wf/gWtev/APDUvhH/AKBGt/8AfmP/AOLo/wCGpfCP/QI1v/vzH/8AF0AeQf8ADNvxD/58rP8A8C1rD8XfB3xb4I0M6tr1tbx2okWMtHcK5yenAr3v/hqXwj/0CNb/AO/Mf/xdcH8YPjfoPj7wK2jaVp+pQTm4STfcxoq4U+zGgDwWvpX9k3/U+IfrF/7NXzVX0r+yb/qfEP1i/wDZqAPo6iiigDlPiPpK6p4OusLmW3HnIfcdf0zSfDnVDqfg21LtukgzC/4f/WxXS3kK3FpLC4ysiFSPY15b8MtXtNEm1XTtTvIrYJLlfNcLk9D1+grkm1Cupd1Y9mgnXy+dNauDTXz0Z6zRWR/wlmgf9Bez/wC/y0f8JZoH/QXs/wDv8tdHPHueZ7Cr/K/uNeisj/hLNA/6C9n/AN/lo/4SzQP+gvZ/9/lo549w9hV/lf3GvRWR/wAJZoH/AEF7P/v8tH/CWaB/0F7P/v8ALRzx7h7Cr/K/uNeisj/hLNA/6C9n/wB/lo/4SzQP+gvZ/wDf5aOePcPYVf5X9xr0Vkf8JZoH/QXs/wDv8tH/AAlmgf8AQXs/+/y0c8e4ewq/yv7jXorI/wCEs0D/AKC9n/3+Wj/hLNA/6C9n/wB/lo549w9hV/lf3GvRWR/wlmgf9Bez/wC/y0f8JZoH/QXs/wDv8tHPHuHsKv8AK/uNeisj/hLNA/6C9n/3+Wj/AISzQP8AoL2f/f5aOePcPYVf5X9xr0Vkf8JZoH/QXs/+/wAtH/CWaB/0F7P/AL/LRzx7h7Cr/K/uNeisj/hLNA/6C9n/AN/lo/4SzQP+gvZ/9/lo549w9hV/lf3GvRVax1C01KEzWFzFcRq20tEwYA4zjj6iirTvsZNNOzLNVNV/5A17/wBe8n/oJq3TZEWWNo5AGVgVYHuDSeqsOL5ZJnypRX0h/wAIV4d/6BNr/wB8Uf8ACFeHf+gTa/8AfFeP/Z0/5j7r/Wih/wA+3+B830V9If8ACFeHf+gTa/8AfFH/AAhXh3/oE2v/AHxR/Z0/5g/1oof8+3+B830V9If8IV4d/wCgTa/98Uf8IV4d/wCgTa/98Uf2dP8AmD/Wih/z7f4HzfRX0h/whXh3/oE2v/fFH/CFeHf+gTa/98Uf2dP+YP8AWih/z7f4HzfRX0h/whXh3/oE2v8A3xR/whXh3/oE2v8A3xR/Z0/5g/1oof8APt/gfN9FfSH/AAhXh3/oE2v/AHxR/wAIV4d/6BNr/wB8Uf2dP+YP9aKH/Pt/gfN9FfSH/CFeHf8AoE2v/fFH/CFeHf8AoE2v/fFH9nT/AJg/1oof8+3+B830V9If8IV4d/6BNr/3xR/whXh3/oE2v/fFH9nT/mD/AFoof8+3+B830V9If8IV4d/6BNr/AN8Uf8IV4d/6BNr/AN8Uf2dP+YP9aKH/AD7f4HzfRX0h/wAIV4d/6BNr/wB8Uf8ACFeHf+gTbf8AfFH9nz/mD/Wih/z7f4Hz1pSCTWbNT0M6D/x4V9QoMIB6CvIviDotjofiLRJtPto7eN5AGCDAJDCvXUOUB9RXTg6bpOUGeTnmKWLhRrRVk0/zFooor0D5k+RP2oP+SnW//Xiv/oTV4vXtH7UH/JTrf/rxX/0Jq8XoA+0PhFpXhqf4T6DJfWenPcNAS7SohYne3XNdn/YnhH/nw0n/AL9x14J4D/Z503xX4G0zW5/EOoW0l5EXMUaKVX5iOPyrof8AhlfSf+hp1P8A74WgD1r+xPCP/PhpP/fuOj+xPCP/AD4aT/37jryX/hlfSf8AoadT/wC+Fo/4ZX0n/oadT/74WgD1r+xPCP8Az4aT/wB+468q/aI03w/a/C15NLtbCK4+1xANAihsZ56VF/wyvpP/AENOp/8AfC1xHxZ+B1j4A8EtrNrrd7euJ0j8qdVC4Y9eKAPDa+lf2Tf9T4h+sX/s1fNVfSv7Jv8AqfEP1i/9moA+jqKKKAGt0r5s8WRiLxdqajtcN/OvpRvu15J4Y0uy1z4k699vt47iJGYgOMgHdiuDGQdTlgurPo8ixKwrq1pK6Uf1PLqK+kP+EK8O/wDQJtf++KP+EK8O/wDQJtf++K5f7On/ADHs/wCtFD/n2/wPm+ivpD/hCvDv/QJtf++KP+EK8O/9Am1/74o/s6f8wf60UP8An2/wPm+ivpD/AIQrw7/0CbX/AL4o/wCEK8O/9Am1/wC+KP7On/MH+tFD/n2/wPm+ivpD/hCvDv8A0CbX/vij/hCvDv8A0CbX/vij+zp/zB/rRQ/59v8AA+b6K+kP+EK8O/8AQJtf++KP+EK8O/8AQJtf++KP7On/ADB/rRQ/59v8D5vor6Q/4Qrw7/0CbX/vij/hCvDv/QJtf++KP7On/MH+tFD/AJ9v8D5vor6Q/wCEK8O/9Am1/wC+KP8AhCvDv/QJtf8Avij+zp/zB/rRQ/59v8D5vor6Q/4Qrw7/ANAm1/74o/4Qrw7/ANAm1/74o/s6f8wf60UP+fb/AAPm+ivpD/hCvDv/AECbX/vij/hCvDv/AECbX/vij+zp/wAwf60UP+fb/A+b6K+kP+EK8O/9Am1/74o/4Qrw7/0CbX/vij+zp/zB/rRQ/wCfb/A5v4M/8ifd/wDX+/8A6LjorttO0uy0m3aDTreO3iZ95WMYBOAM/oKK9SjB06ai+h8djcQsTiJ1oqybLdFFFanIFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHnXxgtidGsLxRzb3HJ9Mj/61dtot4t9olncociWFG/MVn+NdL/tfwnfWwGX8ven1Xn+lYvwr1QX3hRbV2/e2blCO4HauVe7XfmvyPXl+9y2LW8Jfg/+CdzRRRXUeQfIn7UH/JTrf/rxX/0Jq8Xr6D/ak8L3w1/T/EMMLSWTwfZ5HUZ8twxIz9Qa+fMYoA9R8N/tA+L/AAt4ds9F02HTWtbRNkZlgYtjJPJDD1rU/wCGoPHX/PvpH/gM/wD8XXjVFAHsv/DUHjr/AJ99I/8AAZ//AIuj/hqDx1/z76R/4DP/APF141RQB7L/AMNQeOv+ffSP/AZ//i657xr8bPE/jzw+dH1qKwS2MiyE28LK2V6cljXndFABX0r+yb/qfEP1i/8AZq+aq+lf2Tf9T4h+sX/s1AH0dRRRQBBeTrbWks0hwsaFifpXnHwlia5udX1Nx/rpduffOT/Oui+I+rLpfg652tiW4Hkp+PX9M0vw60s6Z4NtAy4kn/fP+P8A9bFcsverpdlc9el+6y6pN/baS+WrOrooorqPICiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAGugdSD0Iwa8osX/AOEH+KMttL8lhqJ+U9hk8fkeK9Zrj/iF4ZOv6GZLUf6ba5eIjq3qtc9eLaUo7o9PLq0IVHSq/BNWfl2fyZ16tuAIpa4v4eeKxrek/Y7x8X9oNkinq4HRq7StYTU4qSOPEUJ4eq6U90Q3dlbahavbX0EdxBIMPHIoZWHuDXJyfCPwDLIXfwpppYnJ/c12VFWYHF/8Kf8Ah/8A9Cnpv/fqj/hT/wAP/wDoU9N/79V2lFAHF/8ACn/h/wD9Cnpv/fqj/hT/AMP/APoU9N/79V2lFAHF/wDCn/h//wBCnpv/AH6rO174HeBtW0W4s7XQ7XT5pFxHc2yYeNux/wDrV6LRQB8AeOfA2reAvEMumavEQMkwzqPkmTsQf6dq9w/ZN/1XiH6xf+zV7P488B6T4+8PSabqsQD4JguFHzwt6g/071558BfA+reA9c8S6Zq8RAzEYZgPkmTLYYGgD2ukb7tLXK+OvFSeHNFby2zeXAKQp6H+9+FTOShFyZtRozr1FTgtWcj4ombxl8QrPQ7XL2to2ZmHT/aP4dK9VijWKFI0GFUYAHauJ+Gvhl9L019S1AE316d5LdVU8/r1ruaxoRdnOW7O7MasOaOHpfDBW9X1YUUUV0HlhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABQRkUUUAeX+NPDl54e1dfFHhwFdrbriJB+Zx6HvXZeFfFVn4m0xZ7dgkyjEsJPKH/CtyRFkQo4DKwwQR1rzHxH4M1Dw5qZ13weWGDultl/XA7j2rklGVGXPBadV+qPapVKeOpqhWdpr4Zd/J/oz1CiuN8KfEKw11Vtrwizvxw0TnAY+x/pXYht3SuiE4zV4s8yvh6uHnyVVZi0UUVZgFFFFABRRRQAUcDmgnArlPFXjzTfDsTRKwub0/dgQ5wff0qJzjBXkzajQqV5qFNXZp+IvEVl4d017u9cZx8kYPzOfQVwPhfRL3xr4gPiPX1ItUb/R4T0OOgHsP1o0Xwtq3jPU11rxYXS2zmK2PG4emOw/nXqMFvHbRJFCipGgwqqMACuZRlXlzS0itl3PVnUp5fTdKk71Hu+3kv1Y9V2jA4HanUUV2HiBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFBAPWiigDjfE/w807Xi1zb/AOh3vXzYxwx9xXMR6r4z8DyeVqMDanYLwJBluPYjkfjXrNNdA4wwBHoa55UE3zRdmenRzGcYeyrJTh2fT0e6OM0j4oaDqICXMj2U3dZhxn6jiuptdUsbxQ1teQyg/wB2QGsjVPAmgasS1zYRo56vD8hP5VzVz8H7UOX0zVLi2PYEbsfjkVN68d0n+BpyZdW1UpQfmrr8NT0cMp6EH8aCwHUj868w/wCFb+JYOLbxNNt7AyOP60f8K58TzcXHiabb7SOf60e2qfyMPqWF/wCghfcz0a51GztE3XF1DEB1LyAVzGrfEzQNMBWK4N5L2SEZ/XpWNB8H4XcPqer3Fx6gDGfxJNdJpnw+8PaUQ0Ngkrjo0x3/AM6OavLZJfiHs8upaynKforL8TjZfEXjDxnJ5Gh2j6fZtwZTwcf7x/pXQeGfhtY6RIt3qTfb73O7c4+VT7Cu1SJY1CooVR0AGKfVRoK/NN3ZFXMZOHsqEVCPlu/V7iKoC4AxS0UV0HlhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//Z"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![youtube.JPG](attachment:youtube.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented by: Mustafa Kolanci\n",
    "\n",
    "Date: 12/08/2021\n",
    "\n",
    "Instructor: Angelica Spratley\n",
    "\n",
    "Github Link: https://github.com/mfurkankolanci/CapstoneProject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I analyze user comments of popular music videos on YouTube. The dataset includes 1,956 comments from Youtube music videos of 5 different artists (PSY, Shakira, LMFAO, Eminem and Katy Perry). This dataset fits the business problem, as the goal is to provide YouTube with a model that can predict music video comments as spam or non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data preparation, the first step is to clean the html tags present in the comments using regex. Then, regex is used again to detect the url's in the comments. After that, comments are tokenized to split each comment into words so that each word is a feature in the model. Stopwords are also removed as they provide little to no value to the spam analysis. Lemmatization is performed to group words with the same meaning together as one word. Then, Term Frequency - Inverse Document Frequency (TF-IDF) is applied in order to assign each word in each comment a numeric value based on its importance across all comments. \n",
    "\n",
    "I use pandas to perform data understanding and filtering, nltk to perform text preprocessing, and sklearn for TF-IDF.\n",
    "\n",
    "For modeling, I use sklearn's MultinomialNB, LogisticRegression and RandomForestClassifier methods. I tune the models using GridSearchCV also provided by sklearn.\n",
    "\n",
    "The best model has a test recall score of 78.8% and test accuracy score of 93.6%, which means that it correctly identifies the comments as spam and not spam 93.6% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data scientist, I was approached by a stakeholder, Youtube's maintenance team. They have noticed that many popular music videos have several spam comments under them. Spam comments are undesired comments that are not related to the music video. They would like to detect these comments in order to improve user experience. Therefore, they have asked me to generate a model that performs spam detection analysis in order to categorize comments as spam and not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 1,956 Youtube comments made between 2013 and 2015. The comments are taken from music videos of PSY, Katy Perry, LMFAO, Eminem and Shakira. There are  five columns, the first column includes the  comment id, the second column is the author of comment, third column is the date of comment,  fourth column is the comment text and fifth column is whether the comment is spam (1) or not (0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing modules necessary for analysis and reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for each artist are in seperate csv files. Let's combine these files into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Psy = pd.read_csv('Data/Youtube01-Psy.csv',encoding= 'unicode_escape')\n",
    "df_katy_perry = pd.read_csv('Data/Youtube02-KatyPerry.csv',encoding= 'unicode_escape')\n",
    "df_LMFAO = pd.read_csv('Data/Youtube03-LMFAO.csv',encoding= 'unicode_escape')\n",
    "df_Eminem = pd.read_csv('Data/Youtube04-Eminem.csv',encoding= 'unicode_escape')\n",
    "df_Shakira = pd.read_csv('Data/Youtube05-Shakira.csv',encoding= 'unicode_escape')\n",
    "df = pd.concat([df_Psy,df_katy_perry,df_LMFAO,df_Eminem,df_Shakira], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell shown below indicates that the ratio of spam and non-spam comments are roughly equal. Therefore, there is no class imbalance to resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.513804\n",
       "0    0.486196\n",
       "Name: CLASS, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CLASS'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`COMMENT_ID`,`AUTHOR` and `DATE` columns provide no useful information in order to determine whether a comment is spam or not, so those columns are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['COMMENT_ID','AUTHOR','DATE'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comments are webscraped and therefore some comments include html syntax and tags. The html needs to be cleaned so that only the comment itself remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "df['CONTENT'] = df['CONTENT'].apply(html.unescape)\n",
    "\n",
    "import re\n",
    "htmlregex = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "\n",
    "def cleanhtml(comment):\n",
    "    html_filtered_comment = re.sub(htmlregex, '', comment)\n",
    "    return html_filtered_comment\n",
    "\n",
    "df['CONTENT'] = df['CONTENT'].apply(cleanhtml)\n",
    "\n",
    "df['CONTENT'] = df['CONTENT'].str.replace('\\ufeff','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, some comments include url's and these url's should be detected. The cell below detects url's and replaces them with the keyword `url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlregex = re.compile(r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\")\n",
    "\n",
    "def detecturl(comment):\n",
    "    url_filtered_comment = re.sub(urlregex, 'url', comment)\n",
    "    return url_filtered_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CONTENT'] = df['CONTENT'].apply(detecturl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, many comments include non-English characters, let's filter each comment such that only characters of the English language and numbers remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphanumericregex = re.compile(r'[^A-Za-z0-9 ]+')\n",
    "def onlyalphanumeric(comment):\n",
    "    alphanumeric_filtered_comment = re.sub(alphanumericregex, '', comment)\n",
    "    return alphanumeric_filtered_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CONTENT'] = df['CONTENT'].apply(onlyalphanumeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's perform some feature engineering on the comments. In the following cell, let's initiate the tokenization, stopword removal and lemmatization of the comments. \n",
    "\n",
    "Tokenization will split each comment into its respective words so that each word will be analyzed by itself in the model. \n",
    "\n",
    "Stopword removal is necessary as stopwords are words that provide little to no value for spam classification. \n",
    "\n",
    "Lemmatization is needed as it allows to group words that are from the same root so that words that have the same meaning are considered the same. This way, the model is not hurt by needlessly increasing dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_and_tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's perform a train-test split. In order to simulate a real-life scenario properly, 90% of the test set comments are non-spam and the rest are spam. The test set consists of 20% of the dataset and the rest is the training set. The training set is equally split between spam and non-spam comments, so that there is no class imbalance during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = df[df['CLASS'] == 1]\n",
    "nonspam = df[df['CLASS'] == 0]\n",
    "\n",
    "spam = spam.sample(n=689)\n",
    "\n",
    "test_spam = spam.sample(n = 33) \n",
    "train_spam = spam.drop(test_spam.index)\n",
    "test_nonspam = nonspam.sample(n = 295)\n",
    "train_nonspam = nonspam.drop(test_nonspam.index)\n",
    "\n",
    "X_train = pd.concat([train_spam,train_nonspam])['CONTENT']\n",
    "X_test = pd.concat([test_spam,test_nonspam])['CONTENT']\n",
    "y_train = pd.concat([train_spam,train_nonspam])['CLASS']\n",
    "y_test = pd.concat([test_spam,test_nonspam])['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is cleaned, lemmatized and tokenized, it can now be converted into a vector format. In order to do so, TF-IDF vectorization will be used. This method is based on the idea that rare words are more valuable for prediction. The method utilizes two metrics:\n",
    "* TF (term frequency) refers to the ratio of number of times a word appear in the document to the total number of words in the document. \n",
    "* IDF (Inverse Document Frequency) refers to the logged ratio of number of documents to the number of documents including the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=10, ngram_range=(1,2), stop_words=stopwords_list, tokenizer=lemmatize_and_tokenize)\n",
    "\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "\n",
    "X_train_df = pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "X_test_df = pd.DataFrame.sparse.from_spmatrix(X_test_vectorized, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top 10 most important words for the spam analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channel',\n",
       " 'check',\n",
       " 'like',\n",
       " 'love',\n",
       " 'please',\n",
       " 'song',\n",
       " 'subscribe',\n",
       " 'url',\n",
       " 'video',\n",
       " 'youtube']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words like `channel`,`check`,`like`,`please` and `subscribe` are observed, which imply that self-advertising comments tend to be the most prevalent spam comments among music videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the top 10 most important bigrams for the spam analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tfidf = TfidfVectorizer(max_features=10, ngram_range=(2,2), stop_words=stopwords_list, tokenizer=lemmatize_and_tokenize)\n",
    "\n",
    "bigram_vectorized = bigram_tfidf.fit_transform(X_train)\n",
    "\n",
    "bigram_df = pd.DataFrame.sparse.from_spmatrix(bigram_vectorized, columns=bigram_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['check channel',\n",
       " 'check video',\n",
       " 'hey guy',\n",
       " 'katy perry',\n",
       " 'like comment',\n",
       " 'love song',\n",
       " 'please check',\n",
       " 'please subscribe',\n",
       " 'subscribe channel',\n",
       " 'video youtube']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigram_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams such as  `check channel`, `check new`, `check playlist`, `check video` are observed, which also imply that self-advertising comments tend to be the most prevalent spam comments among music videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall and accuracy will be used as the performance metrics for the models with recall as the priority metric. There are two types of errors that can be made, false positives and false negatives. False positives, in this case, are comments that are predicted as spam but actually are not spam and false negatives are comments that are predicted as non-spam but actually are spam. \n",
    "\n",
    "For this business problem, false negatives are more important to minimize compared to false positives. If a spam comment is registered as non-spam by the model, no action can be taken toward that comment. At that point, the only way that comment can be detected is if a user notices and decides to report it as spam which defeats the purpose of the model. The model exists so that users don't have to report comments as spam. On the other hand, a non-spam comment detected as spam, while being an error, can still be resolved by notifying the user about the comment and requesting them to take action so that the comment would not be removed.   \n",
    "\n",
    "Recall measures what percent of the spam comments present in a dataset are detected by the model, meaning that a higher recall score means less false negatives are present. This is why recall is the priority metric. As for accuracy, it measures what percent of comments are correctly labeled, which is also a useful success metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: Dummy Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dc = DummyClassifier(strategy='most_frequent')\n",
    "dc.fit(X_train_df,y_train)\n",
    "y_test_pred_dc = dc.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross-validation to observe how the baseline model recall and accuracy do with unseen training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvrs = np.mean(cross_val_score(dc,X_train_df, y_train,cv=5, scoring = 'recall'))\n",
    "cvrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4992395437262357"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvas = np.mean(cross_val_score(dc,X_train_df, y_train,cv=5, scoring = 'accuracy'))\n",
    "cvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix to see how the baseline model does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(dc,X_test_df,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate the recall and accuracy scores of the baseline model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs = recall_score(y_test,y_test_pred_dc)\n",
    "trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899390243902439"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tas = accuracy_score(y_test,y_test_pred_dc)\n",
    "tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation recall score = 20.0 %\n",
      "Mean cross validation accuracy score = 49.9 %\n",
      "Test recall score = 0.0 %\n",
      "Test accuracy score = 89.9 %\n"
     ]
    }
   ],
   "source": [
    "print('Mean cross validation recall score =', round(cvrs*100, 1), '%')\n",
    "print('Mean cross validation accuracy score =', round(cvas*100, 1), '%')\n",
    "print('Test recall score =', round(trs*100, 1), '%')\n",
    "print('Test accuracy score =', round(tas*100, 1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Regressor always picks the majority label, which results with a terrible recall score. Let's look at some other methods to see if we can obtain a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is selected as the first classification model as it is a fast, easy and simple classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_df, y_train)\n",
    "y_test_pred_mnb = mnb.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross-validation to observe how the Naive Bayes model recall and accuracy do with unseen training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444598658339115"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvrs = np.mean(cross_val_score(mnb,X_train_df, y_train,cv=5, scoring = 'recall'))\n",
    "cvrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393318433808377"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvas = np.mean(cross_val_score(mnb,X_train_df, y_train,cv=5, scoring = 'accuracy'))\n",
    "cvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix to see how the Naive Bayes model does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(mnb,X_test_df,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate the recall and accuracy scores of the Naive Bayes model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs = recall_score(y_test,y_test_pred_mnb)\n",
    "trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176829268292683"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tas = accuracy_score(y_test,y_test_pred_mnb)\n",
    "tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation recall score = 84.4 %\n",
      "Mean cross validation accuracy score = 83.9 %\n",
      "Test recall score = 72.7 %\n",
      "Test accuracy score = 91.8 %\n"
     ]
    }
   ],
   "source": [
    "print('Mean cross validation recall score =', round(cvrs*100, 1), '%')\n",
    "print('Mean cross validation accuracy score =', round(cvas*100, 1), '%')\n",
    "print('Test recall score =', round(trs*100, 1), '%')\n",
    "print('Test accuracy score =', round(tas*100, 1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes does much better than the dummy regressor model, however, there is still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is selected as the second model as it is a simple classification algorithm which is computationally efficient. `GridSearchCV` will be utilized in order to try different hyperparameters and optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "logreg = LogisticRegression()\n",
    "param_grid =  {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C' : [1,100,10000]\n",
    "}\n",
    "gs_logreg = GridSearchCV(logreg, param_grid, cv=5, scoring='recall')\n",
    "gs_logreg.fit(X_train_df, y_train)\n",
    "gs_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, solver='newton-cg')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 100, penalty = 'l2', solver = 'newton-cg')\n",
    "lr.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross-validation to observe how the tuned Logistic Regression model recall and accuracy do with unseen training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612190608373813"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvrs = np.mean(cross_val_score(lr,X_train_df, y_train,cv=5, scoring = 'recall'))\n",
    "cvrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9085623893420023"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvas = np.mean(cross_val_score(lr,X_train_df, y_train,cv=5, scoring = 'accuracy'))\n",
    "cvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix to see how the model does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYkklEQVR4nO3de5QV5Znv8e+vAQG5CMgliCCYgAYdRQcxjkeDmlHjOAtNYg4mM8czMUedaEzOOEnUmYkZHc5yxUtiorkQ9UjiLTje8MSBqDHxHgQkChgURQUhIoiCiEh3P+ePqiYb7N69C3p37V39+6xVq3e9VbvqaVg8vLd6SxGBmVkRNeQdgJlZtTjBmVlhOcGZWWE5wZlZYTnBmVlhdc87gFKDB3WL0SN75B2GZfDi4n55h2AZbG7eyAfN72tXrnHCMX1i3VtNFZ07/9ktcyLixF25366oqQQ3emQP5s4ZmXcYlsFJ4z+ZdwiWwZMb7t3la6x7q4m5c0ZVdG634S8O3uUb7oKaSnBmVvsCaKY57zAq4gRnZpkEwdaorImaNyc4M8vMNTgzK6QgaKqTRzyd4Mwss2ac4MysgAJocoIzs6JyDc7MCimAre6DM7MiCsJNVDMrqICm+shvTnBmlk3yJEN9cIIzs4xEE7v0vH6ncYIzs0ySQQYnODMroGQenBOcmRVUs2twZlZE9VSD85LlZpZJIJpoqGgrR9JISQ9Lel7SYklfS8u/I+l1SQvT7aSS71wkaZmkpZJOaC9W1+DMLLMOaqI2AhdExAJJ/YD5kh5Ij30vIq4sPVnSeGAqcACwF/CgpHERbS9O5wRnZpkE4oPotuvXiVgNrE4/b5T0PDCizFemALdHxBZguaRlwCTgyba+4CaqmWWSTPRtqGgDBkuaV7Kd1do1JY0GDgF+nxadJ+lZSTdKGpiWjQBWlHxtJeUTomtwZpZdhkGGtRExsdwJkvoCdwJfj4gNkn4MXEaSSy8DrgK+BK3etOxDY05wZpZJhGiKjmn8SepBktxuiYi7kuvHGyXHfwb8v3R3JVD62r29gVXlru8mqpll1owq2sqRJOAG4PmIuLqkfHjJaacCi9LPs4CpknpKGgOMBeaWu4drcGaWSTLI0CGp40jg74HnJC1Myy4GTpc0gaT5+QpwNkBELJY0E1hCMgJ7brkRVHCCM7OMWgYZdvk6EY/Rer/a/WW+Mw2YVuk9nODMLLMmP6plZkXU8iRDPXCCM7PMmjtoFLXanODMLJPkYXsnODMroEBs7YBHtTqDE5yZZRJBh030rTYnODPLqP1JvLXCCc7MMglcgzOzAvMgg5kVUiC/k8HMiil5bWB9pI76iNLMaohf/GxmBRX4SQYzKzDX4MyskCLkGpyZFVMyyOBHtcyskDrunQzV5gRnZpkkgwzugzOzgvKTDGZWSH6SwcwKrSNeOtMZnODMLJMI2NrsBGdmBZQ0UZ3gzKyg/CRDF7Hm9R5c8bVRrF/TAzUEJ/3dOk798lqmnb0PK1/qBcCmDd3o07+JHz+4FICXl/TiB98ayaaNDTQ0wA/vf4HdekWev0aX9fX/WMqkT77F22/14CtTJgIwZr93Oe+SF+m9exNvvN6L735zfzZv8j+VFp4mkpJ0InAN0A24PiIur+b98tCte3DWt1cx9qDNvPduA+edOI5Dj97Iv/z01W3n/PTf96JPvyYAmhrhu1/dh2/84FU+esD7bHirG916OLnl5cG7h3HfLXtxweVLt5V97dIXuP6KfVk0bwB//Zk/8bkvreQXPxydX5A1p36aqFWLUlI34Drg08B44HRJ46t1v7zsOayRsQdtBmD3vs2M/NgW1q7use14BDwyawDHnLIegPm/68eYj2/mowe8D0D/QU10q4+nXgpp0fwBbHynx3Zle4/ZzKJ5ewDwzBMDOPL4tXmEVtOa0/cytLflrZppeBKwLCJejogPgNuBKVW8X+7+tGI3XlrUm/0PfW9b2aLf92HgkEZG7PsBACtf7oUEF5++L+ceP46Z1w3NK1xrwysv9uETx64D4KgT1jL4I1tyjqi2JKOo3Sra8lbNBDcCWFGyvzIt246ksyTNkzTvzXVNVQynujZvauCyL4/mnEtfp0+/5m3lD98zkMlp7Q2SJuqiuX341rWvctU9L/LE7D145tG+eYRsbfj+v47j5NNXcc0dC+jdp4nGrfnXRGpJy0TfSra8VbMPrrXf7kOdTRExHZgOMPHg+uxpb9wKl315NMd+Zj3/7aR3tpU3NcLj9+/BtbNf2FY2ZPhWDjpiE3vsmSTzw47dwLLnenPIUe92etzWupXLd+df/9dBAIzY5z0OO/qtnCOqPbXQ/KxENWtwK4GRJft7A6uqeL9cRMDVF4xi5NgtfPbsN7c7tuDRfoz82BaG7LV1W9lfTt7I8iW9eP890dQIzz7Zl1Hj3ASqJXsMSroTpGDqOa9x/8zhOUdUW1pGUbt6De5pYKykMcDrwFTgC1W8Xy4Wz+3DQ/85iDEf38w/fmo/AP7holVMOm4jv7t3++YpQL8BTXzm7Df56knjkGDSsRs4/FMb8gjdgG9e8TwHTXqH/gO28vPfPMXN1+5D792bOfkLyf/Fjz8wmAfuGpZzlLWnXkZRq5bgIqJR0nnAHJJpIjdGxOJq3S8vBx6+iTmrFrZ67J+//1qr5cd9dj3HfXZ9q8esc333Gx9vtfzemz/UXWypCNHYAQlO0kjg58BHgGZgekRcI2kQ8EtgNPAK8PmIWJ9+5yLgTKAJOD8i5pS7R1XnwUXE/cD91byHmXW+Dmp+NgIXRMQCSf2A+ZIeAP4n8FBEXC7pQuBC4FvpNLOpwAHAXsCDksZFRJujk/VRzzSzmtFRfXARsToiFqSfNwLPk8y0mALMSE+bAZySfp4C3B4RWyJiObCMZDpam/z8iZlllqEGN1jSvJL96enMie1IGg0cAvweGBYRqyFJgpJaJouOAJ4q+VqrU89KOcGZWSYZF7xcGxETy50gqS9wJ/D1iNggtXntiqaelXIT1cwy66hHtST1IElut0TEXWnxG5KGp8eHA2vS8sxTz5zgzCyTCGhsbqhoK0dJVe0G4PmIuLrk0CzgjPTzGcC9JeVTJfVMp5+NBeaWu4ebqGaWWQeNoh4J/D3wnKSFadnFwOXATElnAq8BpwFExGJJM4ElJCOw55YbQQUnODPLqKNeOhMRj9F6vxrAcW18ZxowrdJ7OMGZWWZRA49hVcIJzswyq5eH7Z3gzCyTCC9ZbmaFJZr82kAzKyr3wZlZIfmtWmZWXJH0w9UDJzgzy8yjqGZWSOFBBjMrMjdRzaywPIpqZoUU4QRnZgXmaSJmVljugzOzQgpEs0dRzayo6qQC5wRnZhl5kMHMCq1OqnBOcGaWWd3X4CT9kDJ5OiLOr0pEZlbTAmhurvMEB8wrc8zMuqoA6r0GFxEzSvcl9YmITdUPycxqXb3Mg2t3MoukIyQtAZ5P9w+W9KOqR2ZmtSsq3HJWyWy97wMnAOsAIuIPwNFVjMnMapqIqGzLW0WjqBGxQtou2LJvkzazgquB2lklKklwKyT9FRCSdgPOJ22umlkXFBB1MopaSRP1HOBcYATwOjAh3TezLksVbvlqtwYXEWuBL3ZCLGZWL+qkiVrJKOq+ku6T9KakNZLulbRvZwRnZjWqQKOotwIzgeHAXsAdwG3VDMrMaljLRN9KtpxVkuAUEb+IiMZ0u5mayM1mlpeIyra8tZngJA2SNAh4WNKFkkZL2kfSN4FfdV6IZlZzmlXZ1g5JN6ZdX4tKyr4j6XVJC9PtpJJjF0laJmmppBPau365QYb5JDW1lijPLjkWwGXtRm9mhaSOq53dBFwL/HyH8u9FxJXb3VMaD0wFDiDpLntQ0riIaHNebrlnUcfsbMRmVmAdOIAQEY9IGl3h6VOA2yNiC7Bc0jJgEvBkW1+o6EkGSQcC44FeJYHtmHHNrEvINIAwWFLpykTTI2J6Bd87T9L/IFnV6IKIWE8yF/epknNWpmVtajfBSboEmEyS4O4HPg08xoerlGbWVVReg1sbERMzXv3HJF1gLV1hVwFfovWZw2UjqWQU9XPAccCfIuIfgIOBnlmiNbOCaa5w2wkR8UZENEVEM/AzkmYoJDW2kSWn7g2sKnetShLc5vRGjZL6A2sAT/Q166qqPA9O0vCS3VOBlhHWWcBUST0ljQHGAnPLXauSPrh5kgaQZNL5wLvtXdTMiq2jRlEl3UbSBTZY0krgEmCypAkkqfQV0hkcEbFY0kxgCdAInFtuBBUqexb1K+nHn0iaDfSPiGd36rcxs2LouFHU01spvqHM+dOAaZVev9xLZw4tdywiFlR6EzOzPJSrwV1V5lgAx3ZwLLzw7O6csNeEjr6sVVH34b3zDsGyeLdjng/twIm+VVVuou8xnRmImdWJoKLHsGqBX/xsZtnVew3OzKwtdd9ENTNrU50kuEpW9JWkv5P07XR/lKRJ7X3PzAqsQCv6/gg4AmiZr7IRuK5qEZlZTVNUvuWtkibq4RFxqKRnACJiffr6QDPrqgo0irpVUjfSCqekIez0Y7RmVgS1UDurRCVN1B8AdwNDJU0jWSrp/1Q1KjOrbXXSB1fJs6i3SJpPsmSSgFMiwm+2N+uqaqR/rRKVLHg5CngPuK+0LCJeq2ZgZlbDipLgSN6g1fLymV7AGGApyYsfzKwLUp30wlfSRP2L0v10lZGz2zjdzKxmZH6SISIWSDqsGsGYWZ0oShNV0j+V7DYAhwJvVi0iM6ttRRpkAPqVfG4k6ZO7szrhmFldKEKCSyf49o2Ib3RSPGZWD+o9wUnqHhGN5ZYuN7OuRxRjFHUuSX/bQkmzgDuATS0HI+KuKsdmZrWoYH1wg4B1JO9gaJkPF4ATnFlXVYAENzQdQV3EnxNbizr59cysKuokA5RLcN2Avmyf2FrUya9nZtVQhCbq6oi4tNMiMbP6UYAEVx8r2plZ54pijKIe12lRmFl9qfcaXES81ZmBmFn9KEIfnJlZ65zgzKyQamQ58ko4wZlZJqJ+mqiVvHTGzGw7HfVeVEk3SlojaVFJ2SBJD0h6Mf05sOTYRZKWSVoq6YT2ru8EZ2bZddxbtW4CTtyh7ELgoYgYCzyU7iNpPDCV5HUJJwI/Slc8apMTnJll10EJLiIeAXacsTEFmJF+ngGcUlJ+e0RsiYjlwDJgUrnrO8GZWTYVNk93oZ9uWESsBkh/Dk3LRwArSs5bmZa1yYMMZpZd5clrsKR5JfvTI2L6Tt4183PxTnBmllmGR7XWRsTEjJd/Q9LwiFgtaTiwJi1fCYwsOW9vYFW5C7mJamaZVbmJOgs4I/18BnBvSflUST0ljQHGkizM2ybX4Mwsmw6c6CvpNmAySVN2JXAJcDkwU9KZwGvAaQARsVjSTGAJyQuwzo2IpnLXd4Izs+w6KMFFxOltHGp1sY+ImAZMq/T6TnBmlkk9PcngBGdmmam5PjKcE5yZZeOH7c2syNxENbPicoIzs6JyDc7MissJzswKqSBv1TIz+xDPgzOzYov6yHBOcGaWmWtwxt4ffZ+Lf/Lqtv2PjPqAX1zxEe6+fkiOUVmpwcM2c8GlzzFwzw9obobZd49k1m37APC3//1VTv78azQ1iacfG8L//cF+OUdbIzzRN3mZBHAysCYiDqzWfWrZypd68ZW/Tv5RNDQEtyxYwuP/tUfOUVmppqYGrv/e/rz0x/703r2Ra25+kmee2pOBe27hE59cw7lTj6RxawN7DNySd6g1pV4GGaq5HtxNfPhlEl3WhKPeZfWru7Hm9d3yDsVKrF/bk5f+2B+Aze91Z8XyPuw59H1O+twK7rhpXxq3Jv9E3lnfM88wa46aK9vyVrUE18bLJLqsyVPW89t7BrZ/ouVm6PDN7Lv/RpYuGsCIUe9xwCHruXrGU1w+fS5jx7+Td3i1I0gGGSrZcpb7ir6SzpI0T9K8rRSzGdC9RzOfOH4Dj9zn5mmt6tW7kX+5YiE/u3J/Nm/qTkO3oG//rfzTGYdz4zXjuPDyP1A3HU+doMor+naY3BNcREyPiIkRMbEHxWwGHHbsRpY915u31/bIOxRrRbfuzVx8xUIe/q/hPPHwMADWrenJE78ZBogXFg8gAvoP2JpvoLWk496LWlW5J7iuYPIpb7t5WrOCr/3bYlYs78M9t4zeVvrkb4dx8GHrANhr1Ca6dw82vO3/oODPE33roQbnaSJV1rN3M4cetZFrvrl33qFYK8ZPeJvjTl7F8hf78sNbnwBgxnVjeeDeEXz9kkVc98vHaWwUV3/nQFp/a10XFOEFL1t7mURE3FCt+9WqLZsbOO3ALjlLpi4sWTiQv/nLE1o9duW/HdTJ0dSR+shv1UtwZV4mYWZ1rhaan5VwE9XMsgmgqzdRzazA6iO/OcGZWXZuoppZYXX5UVQzK6gamcRbCSc4M8skmehbHxnOCc7MsquBlUIq4QRnZpm5BmdmxeQ+ODMrLj+LamZF5iaqmRVSB774WdIrwEagCWiMiImSBgG/BEYDrwCfj4j1O3N9rwdnZtl17JLlx0TEhIiYmO5fCDwUEWOBh9L9neIEZ2bZVXdF3ynAjPTzDOCUnb2QE5yZZabm5oo2kvUg55VsZ+1wqQB+LWl+ybFhEbEaIP05dGfjdB+cmWUTZJnou7ak6dmaIyNilaShwAOS/rir4ZVyDc7MMhGBorKtPRGxKv25BrgbmAS8IWk4QPpzzc7G6gRnZtl1wCCDpD6S+rV8Bo4HFgGzgDPS084A7t3ZMN1ENbPsOmYe3DDgbkmQ5KJbI2K2pKeBmZLOBF4DTtvZGzjBmVk22frg2r5MxMvAwa2UrwOO2/U7OMGZ2U5IR0hrnhOcmWWUaRJvrpzgzCybwAnOzAqsPlqoTnBmlp0XvDSz4nKCM7NCioCm+mijOsGZWXauwZlZYTnBmVkhBeB3MphZMQWE++DMrIgCDzKYWYG5D87MCssJzsyKyQ/bm1lRBeDlksyssFyDM7Ni8qNaZlZUAeF5cGZWWH6SwcwKy31wZlZIER5FNbMCcw3OzIopiKamvIOoiBOcmWXj5ZLMrNA8TcTMiiiAcA3OzAopvOClmRVYvQwyKGpouFfSm8CrecdRBYOBtXkHYZkU9e9sn4gYsisXkDSb5M+nEmsj4sRdud+uqKkEV1SS5kXExLzjsMr576wYGvIOwMysWpzgzKywnOA6x/S8A7DM/HdWAO6DM7PCcg3OzArLCc7MCssJrooknShpqaRlki7MOx5rn6QbJa2RtCjvWGzXOcFViaRuwHXAp4HxwOmSxucblVXgJiC3ianWsZzgqmcSsCwiXo6ID4DbgSk5x2TtiIhHgLfyjsM6hhNc9YwAVpTsr0zLzKyTOMFVj1op85wcs07kBFc9K4GRJft7A6tyisWsS3KCq56ngbGSxkjaDZgKzMo5JrMuxQmuSiKiETgPmAM8D8yMiMX5RmXtkXQb8CSwn6SVks7MOybbeX5Uy8wKyzU4MyssJzgzKywnODMrLCc4MyssJzgzKywnuDoiqUnSQkmLJN0hafdduNZNkj6Xfr6+3EIAkiZL+quduMcrkj709qW2ync4592M9/qOpH/OGqMVmxNcfdkcERMi4kDgA+Cc0oPpCiaZRcSXI2JJmVMmA5kTnFnenODq16PAx9La1cOSbgWek9RN0hWSnpb0rKSzAZS4VtISSb8ChrZcSNJvJU1MP58oaYGkP0h6SNJokkT6v9Pa41GShki6M73H05KOTL+7p6RfS3pG0k9p/Xnc7Ui6R9J8SYslnbXDsavSWB6SNCQt+6ik2el3HpW0f4f8aVoh+c32dUhSd5J15manRZOAAyNieZok3omIwyT1BB6X9GvgEGA/4C+AYcAS4MYdrjsE+BlwdHqtQRHxlqSfAO9GxJXpebcC34uIxySNInla4+PAJcBjEXGppL8BtktYbfhSeo/ewNOS7oyIdUAfYEFEXCDp2+m1zyN5Gcw5EfGipMOBHwHH7sQfo3UBTnD1pbekhennR4EbSJqOcyNieVp+PHBQS/8asAcwFjgauC0imoBVkn7TyvU/ATzScq2IaGtdtE8B46VtFbT+kvql9/hM+t1fSVpfwe90vqRT088j01jXAc3AL9Pym4G7JPVNf987Su7ds4J7WBflBFdfNkfEhNKC9B/6ptIi4KsRMWeH806i/eWaVME5kHRtHBERm1uJpeJn/yRNJkmWR0TEe5J+C/Rq4/RI7/v2jn8GZm1xH1zxzAH+UVIPAEnjJPUBHgGmpn10w4FjWvnuk8AnJY1JvzsoLd8I9Cs579ckzUXS8yakHx8BvpiWfRoY2E6sewDr0+S2P0kNskUD0FIL/QJJ03cDsFzSaek9JOngdu5hXZgTXPFcT9K/tiB9ccpPSWrqdwMvAs8BPwZ+t+MXI+JNkn6zuyT9gT83Ee8DTm0ZZADOByamgxhL+PNo7r8DR0taQNJUfq2dWGcD3SU9C1wGPFVybBNwgKT5JH1sl6blXwTOTONbjJeBtzK8moiZFZZrcGZWWE5wZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWP8f88ZTxBNxqWcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(lr,X_test_df,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate the recall and accuracy scores of the tuned Logistic Regression model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_logreg = lr.predict(X_test_df)\n",
    "trs = recall_score(y_test,y_test_pred_logreg)\n",
    "trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207317073170732"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tas = accuracy_score(y_test,y_test_pred_logreg)\n",
    "tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation recall score = 86.1 %\n",
      "Mean cross validation accuracy score = 90.9 %\n",
      "Test recall score = 78.8 %\n",
      "Test accuracy score = 92.1 %\n"
     ]
    }
   ],
   "source": [
    "print('Mean cross validation recall score =', round(cvrs*100, 1), '%')\n",
    "print('Mean cross validation accuracy score =', round(cvas*100, 1), '%')\n",
    "print('Test recall score =', round(trs*100, 1), '%')\n",
    "print('Test accuracy score =', round(tas*100, 1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression does slightly better on the test set than the Naive Bayes model. Let's try a more advanced model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is selected as the third and final model as it is an ensemble model which means it is more immune to overfitting and usually has stronger performance compared to simpler models such as Logistic Regression and Naive Bayes. Once again `GridSearchCV` will be utilized in order to try different hyperparameters and optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "param_grid = {'n_estimators':[100,200,500],\n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth':[50,100,200]           \n",
    "}\n",
    "gs_forest = GridSearchCV(forest, param_grid, cv=5, scoring='recall')\n",
    "gs_forest.fit(X_train_df, y_train)\n",
    "gs_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=50)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion = 'entropy',max_depth = 50, n_estimators=100)\n",
    "rf.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross-validation to observe how the tuned random forest model recall and accuracy do with unseen training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475017349063151"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvrs = np.mean(cross_val_score(rf,X_train_df, y_train,cv=5, scoring = 'recall'))\n",
    "cvrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039880416799699"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvas = np.mean(cross_val_score(rf,X_train_df, y_train,cv=5, scoring = 'accuracy'))\n",
    "cvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix to see how the tuned random forest does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rf,X_test_df,y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate the recall and accuracy scores of the tuned random forest model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_rf = rf.predict(X_test_df)\n",
    "trs = recall_score(y_test,y_test_pred_rf)\n",
    "trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9359756097560976"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tas = accuracy_score(y_test,y_test_pred_rf)\n",
    "tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation recall score = 84.8 %\n",
      "Mean cross validation accuracy score = 90.4 %\n",
      "Test recall score = 78.8 %\n",
      "Test accuracy score = 93.6 %\n"
     ]
    }
   ],
   "source": [
    "print('Mean cross validation recall score =', round(cvrs*100, 1), '%')\n",
    "print('Mean cross validation accuracy score =', round(cvas*100, 1), '%')\n",
    "print('Test recall score =', round(trs*100, 1), '%')\n",
    "print('Test accuracy score =', round(tas*100, 1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest does slightly better on the test set than the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to generate a model to perform spam analysis on popular music video comments on YouTube. To do so, three classification models are created, with the best model having a test recall score of 78.8% and test accuracy score of 93.6%. The project provides the stakeholder with the model so that it can be applied on other YouTube comments.\n",
    "\n",
    "I recommend that the model should only used to detect spam comments under music videos. The dataset only includes music video comments, therefore one should be cautious of applying this model on comments from non-music videos. \n",
    "\n",
    "Another recommendation is that this model should be used to flag the detected spam comments for further analysis and not remove them. Although the model has high spam detection accuracy, it shouldn't be used to remove a comment right away as removing a comment disrupts a user's ability to freely express their opinion on YouTube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used has around 2,000 comments. Popular music videos tend to have hundreds of thousands of comments each with many non-English comments, therefore the model can be altered to analyze much more English and non-English comments as well for a wider range of spam detection capability. \n",
    "\n",
    "Another future work that can be done is identifying accounts that tend to make spam comments. The model can be used to track the frequency and amount of spam comments made by each account and therefore can flag accounts as spam or non-spam. \n",
    "\n",
    "Finally, the model can be tested on non-music video comments as well. If the model performance doesn't suffer, the model can be generalized to videos with other genres as well and if it does suffer, alternative models can be generated for comments of different genres."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c94be41889154d41bf43aca8d1a8d1cd64b97c119170e03e2ed46ca87183f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
